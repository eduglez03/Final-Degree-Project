{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526843ca",
   "metadata": {},
   "source": [
    "# Trabajo de Fin de Grado\n",
    "### Grado en Ingeniería Informática\n",
    "\n",
    "## Estudio del problema de la generalización de modelos de aprendizaje profundo entrenados para el diagnóstico del glaucoma.\n",
    "\n",
    "### Eduardo González Gutiérrez\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbf85b5",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4194977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import scipy\n",
    "import shutil\n",
    "import random\n",
    "import tensorflow as tf \n",
    "from pathlib import Path\n",
    "from tensorflow import keras \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K  \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50 \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la versión de TensorFlow que se va a utilizar\n",
    "print(\"Versión de TensorFlow:\", tf.__version__) \n",
    "\n",
    "# Mostramos la GPU que se va a utilizar\n",
    "print(\"GPUs disponibles:\", tf.config.list_physical_devices('GPU')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae6e28",
   "metadata": {},
   "source": [
    "## Rutas Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "\n",
    "# Definimos las rutas del directorio\n",
    "fold_dir = os.path.join(base_dir, 'Dataset', 'Entrenamientos', 'Imagenes-Segmentadas', 'validacion_cruzada', 'fold_5')\n",
    "\n",
    "# Dentro del directorio fold_dir, accedemos a los subdirectorios train y val\n",
    "train_dir = os.path.join(fold_dir, 'train')\n",
    "validation_dir = os.path.join(fold_dir, 'val')\n",
    "\n",
    "# Definimos la ruta del directorio de test\n",
    "test_dir = os.path.join(base_dir, 'Dataset', 'Evaluacion', 'REFUGE', 'Mascaras')\n",
    "\n",
    "\n",
    "# Diccionario con las rutas\n",
    "dirs = {'Train': train_dir, 'Validation': validation_dir, 'Test': test_dir}\n",
    "\n",
    "# Definimos las clases de imágenes en las cuales se clasifcan las imágenes en los directorios\n",
    "clases = ['Normales', 'Glaucomas']\n",
    "\n",
    "# Imprimimos las rutas de los directorios y el número de imágenes en cada clase\n",
    "for nombre_dir, ruta_dir in dirs.items():\n",
    "    print(f\"\\n--- {nombre_dir} ---\")\n",
    "    print(\"Ruta:\", ruta_dir)\n",
    "    for clase in clases:\n",
    "        ruta_clase = os.path.join(ruta_dir, clase)\n",
    "        if os.path.exists(ruta_clase):\n",
    "            num_imagenes = len([\n",
    "                f for f in os.listdir(ruta_clase)\n",
    "                if os.path.isfile(os.path.join(ruta_clase, f))\n",
    "            ])\n",
    "            print(f\"{clase}: {num_imagenes} imágenes\")\n",
    "        else:\n",
    "            print(f\"No se encontró la carpeta {ruta_clase}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ea262",
   "metadata": {},
   "source": [
    "## Funciones de preprocesado de imágenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208380f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de preprocesado para redes ResNet50\n",
    "def preprocess_input(x):\n",
    "  # Obtenemos el formato de los datos de imagen\n",
    "  data_format = K.image_data_format()\n",
    "  assert data_format in {'channels_last', 'channels_first'}\n",
    "\n",
    "  # Preprocesamos la imagen según el formato de datos\n",
    "  # En el formato 'channels_first', la imagen tiene la forma (canales, alto, ancho)\n",
    "   # En el formato 'channels_last', la imagen tiene la forma (alto, ancho, canales)\n",
    "  if data_format == 'channels_first':\n",
    "    # Convertimos de 'RGB' a 'BGR' invirtiendo el orden de los canales\n",
    "    x = x[::-1, :, :]\n",
    "    \n",
    "    # Centramos los valores de píxel restando la media por canal.\n",
    "    x[0, :, :] -= 103.939\n",
    "    x[1, :, :] -= 116.779\n",
    "    x[2, :, :] -= 123.68\n",
    "  else:\n",
    "    # Convertimos de 'RGB' a 'BGR' invirtiendo el eje de los canales\n",
    "    x = x[:, :, ::-1]\n",
    "\n",
    "    # Centramos los valores de píxel restando la media por canal.\n",
    "    x[:, :, 0] -= 103.939\n",
    "    x[:, :, 1] -= 116.779\n",
    "    x[:, :, 2] -= 123.68\n",
    "  return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa57595c",
   "metadata": {},
   "source": [
    "## Función de Construcción del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928992a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para construir el modelo ResNet50 con las capas de salida personalizadas adaptadas a nuestro problema de clasificación binaria (glaucoma vs no glaucoma)\n",
    "def build_model(input_shape_size, weights_source, trainable_condition):\n",
    "    \n",
    "    # Cargamos el modelo preentrenado ResNet50 sin la capa de salida (include_top=False) y especificamos el tamaño de entrada (input_shape_size).\n",
    "    pre_trained_model = ResNet50(input_shape=input_shape_size, include_top=False, weights=weights_source)\n",
    "\n",
    "    # Definimos si las capas del modelo preentrenado deben ser entrenables o no.\n",
    "    pre_trained_model.trainable = trainable_condition\n",
    "\n",
    "    # Añadimos una capa de normalización por lotes (Batch Normalization) para mejorar la estabilidad del entrenamiento\n",
    "    x = GlobalAveragePooling2D()(pre_trained_model.output)\n",
    "\n",
    "    # Añadimos un Dropout para reducir el sobreajuste\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Añadimos una nueva capa final que clasifique en 2 clases (glaucoma y no glaucoma)\n",
    "    outputs = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    # Creamos el modelo final combinando la entrada del modelo preentrenado y la salida personalizada\n",
    "    model = Model(inputs=pre_trained_model.input, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f1a959",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generadores de imágenes con redimensionamiento y normalización para ResNet50\n",
    "image_size = (224, 224)\n",
    "\n",
    "# Creamos el objeto ImageDataGenerator para el Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, # Llamamos a función de preprocesado\n",
    "    rotation_range=30, # Rotación entre -20º y 20º\n",
    "    horizontal_flip=True, # Flip horizontal\n",
    "    brightness_range=[0.8, 1.2], # Variación de brillo\n",
    ")\n",
    "\n",
    "# Generador para validación y test, solo con preprocesamiento, sin aumentos de datos\n",
    "validation_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Creamos el generador que cargará las imágenes de entrenamiento, redimensiona las imágenes, aplica aumentos, las agrupa en batches de 32 y define las clases objetivo\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=image_size, batch_size=32, classes=['Normales', 'Glaucomas'])\n",
    "\n",
    "# Generador para el conjunto de validación, sin aumentos, solo preprocesamiento\n",
    "validation_generator = validation_test_datagen.flow_from_directory(validation_dir, target_size=image_size, batch_size=32, classes=['Normales', 'Glaucomas'])\n",
    "\n",
    "# Generador para el conjunto de test, sin barajar las imágenes (shuffle=False) para evaluación ordenada\n",
    "test_generator = validation_test_datagen.flow_from_directory(test_dir, target_size=image_size, batch_size=32, classes=['Normales', 'Glaucomas'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a9aab",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la forma de entrada que tendrá la red: imágenes RGB de 224x224 píxeles\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Indicamos que usaremos pesos preentrenados en ImageNet para la inicialización del modelo\n",
    "weights = 'imagenet'\n",
    "\n",
    "# Indicamos que las capas preentrenadas no serán entrenables.\n",
    "trainable_condition = False\n",
    "\n",
    "# Llamamos a la función que define el modelo\n",
    "model = build_model(input_shape, weights, trainable_condition)\n",
    "\n",
    "# Se muestra un resumen de la red\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff032d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el entrenamiento de la red con los siguientes parámetros:\n",
    "#   - loss='categorical_crossentropy': Función de pérdida para clasificación binaria (glaucoma vs no glaucoma)\n",
    "#   - optimizer=Adam: Optimizador que ajusta los pesos\n",
    "#   - learning_rate=1e-4: Tasa de aprendizaje\n",
    "#   - metrics: Accuracy: Porcentaje de aciertos\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=1e-4),   \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='ResNet50-FineTuning-Fold5-600-epochs-Originales'\n",
    "\n",
    "# Definimos un callback para guardar automáticamente el mejor modelo durante el entrenamiento\n",
    "checkpoint = ModelCheckpoint(\n",
    "        model_name,  # Nombre del archivo donde se guardará el mejor modelo\n",
    "        monitor=\"val_accuracy\",  # Monitoreamos la precisión en validación\n",
    "        save_best_only=True,  # Guarda solo si es el mejor hasta el momento\n",
    "        mode=\"max\",  # Queremos la mayor precisión posible\n",
    "        verbose=1,  # Muestra mensajes cuando guarda un nuevo mejor modelo\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo usando el generador de entrenamiento y validación\n",
    "history_fine_tuning = model.fit(\n",
    "    train_generator, # Datos de entrenamiento con aumentos y preprocesamiento\n",
    "    epochs=600, # Número total de épocas para entrenar\n",
    "    batch_size=32, # Tamaño de lote para cada iteración\n",
    "    callbacks=[checkpoint], # Callback para guardar el mejor modelo durante el entrenamiento\n",
    "    validation_data=validation_generator, # Datos para validación al final de cada época\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el mejor modelo guardado durante el entrenamiento\n",
    "model.load_weights(model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb814160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "# Primero evaluamos el último modelo por si acaso sea el mejor\n",
    "# Después evaluamos el mejor modelo guardado\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "\n",
    "# Obtener la cantidad de épocas realmente entrenadas\n",
    "epochs_trained = len(history_fine_tuning.history['loss'])\n",
    "print(f\"El entrenamiento se detuvo en la época: {epochs_trained}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3eebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos de entrenamiento\n",
    "acc = history_fine_tuning.history['accuracy']\n",
    "val_acc = history_fine_tuning.history['val_accuracy']\n",
    "loss = history_fine_tuning.history['loss']\n",
    "val_loss = history_fine_tuning.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig('Resultados/ResNet50/Imagenes-Originales/Fine-Tuning/ResNet50-FineTuning-Fold5-600-epochs-Graph.png')  # Guardar la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda solo los pesos del modelo\n",
    "model.save_weights('Resultados/ResNet50/Imagenes-Originales/Fine-Tuning/ResNet50-FineTuning-Fold5 -600-epochs.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d09a6",
   "metadata": {},
   "source": [
    "## Deep Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dea7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la forma de entrada que tendrá la red: imágenes RGB de 224x224 píxeles\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Indicamos que usaremos pesos preentrenados en ImageNet para la inicialización del modelo\n",
    "weights = 'imagenet'\n",
    "\n",
    "# Indicamos que las capas preentrenadas sí serán entrenables.\n",
    "trainable_condition = True\n",
    "\n",
    "# Llamamos a la función que define el modelo\n",
    "model = build_model(input_shape, weights, trainable_condition)\n",
    "\n",
    "# Cargamos los pesos del modelo previamente entrenado con fine-tuning\n",
    "model.load_weights('Resultados/ResNet50/Imagenes-Segmentadas/Fine-Tuning/ResNet50-FineTuning-Fold2-600-epochs.h5') \n",
    "\n",
    "# Se muestra un resumen de la red\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab01aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el entrenamiento de la red con los siguientes parámetros:\n",
    "#   - loss='categorical_crossentropy': Función de pérdida para clasificación binaria (glaucoma vs no glaucoma)\n",
    "#   - optimizer=Adam: Optimizador que ajusta los pesos\n",
    "#   - learning_rate=1e-5: Tasa de aprendizaje\n",
    "#   - metrics: Accuracy: Porcentaje de aciertos\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=1e-5),   \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='ResNet50-DeepTuning-Fold5-PeorFineTuning-600-epochs'\n",
    "\n",
    "# Definimos un callback para guardar automáticamente el mejor modelo durante el entrenamiento\n",
    "checkpoint = ModelCheckpoint(\n",
    "        model_name,  # Nombre del archivo donde se guardará el mejor modelo\n",
    "        monitor=\"val_accuracy\",  # Monitoreamos la precisión en validación\n",
    "        save_best_only=True,  # Guarda solo si es el mejor hasta el momento\n",
    "        mode=\"max\",  # Queremos la mayor precisión posible\n",
    "        verbose=1,  # Muestra mensajes cuando guarda un nuevo mejor modelo\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo usando el generador de entrenamiento y validación\n",
    "history_fine_tuning = model.fit(\n",
    "    train_generator, # Datos de entrenamiento con aumentos y preprocesamiento\n",
    "    epochs=600, # Número total de épocas para entrenar\n",
    "    batch_size=32, # Tamaño de lote para cada iteración\n",
    "    callbacks=[checkpoint], # Callback para guardar el mejor modelo durante el entrenamiento\n",
    "    validation_data=validation_generator, # Datos para validación al final de cada época\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440ca368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el mejor modelo guardado durante el entrenamiento\n",
    "model.load_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "# Primero evaluamos el último modelo por si acaso sea el mejor\n",
    "# Después evaluamos el mejor modelo guardado\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "\n",
    "# Obtener la cantidad de épocas realmente entrenadas\n",
    "epochs_trained = len(history_fine_tuning.history['loss'])\n",
    "print(f\"El entrenamiento se detuvo en la época: {epochs_trained}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos de entrenamiento\n",
    "acc = history_fine_tuning.history['accuracy']\n",
    "val_acc = history_fine_tuning.history['val_accuracy']\n",
    "loss = history_fine_tuning.history['loss']\n",
    "val_loss = history_fine_tuning.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig('Resultados/ResNet50/Imagenes-Segmentadas/Deep-Tuning/Peor-Fine-Tuning/ResNet50-DeepTuning-Fold5-600-epochs-Graph.png')  # Guardar la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c728152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda solo los pesos del modelo\n",
    "model.save_weights('Resultados/ResNet50/Imagenes-Segmentadas/Deep-Tuning/Peor-Fine-Tuning/ResNet50-DeepTuning-Fold5-600-epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d1e525",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3128b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la forma de entrada que tendrá la red: imágenes RGB de 224x224 píxeles\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Indicamos que usaremos pesos preentrenados en ImageNet para la inicialización del modelo\n",
    "weights = 'imagenet'\n",
    "\n",
    "# Indicamos si las capas preentrenadas serán entrenadas o no. \n",
    "trainable_condition = False\n",
    "\n",
    "# Llamamos a la función que define el modelo\n",
    "model = build_model(input_shape, weights, trainable_condition)\n",
    "\n",
    "# Cargamos los pesos del modelo previamente entrenado y que ha dado mejores resultados entre los deep tunings y fine tunings\n",
    "model.load_weights('Resultados/ResNet50/Imagenes-Segmentadas/Fine-Tuning/ResNet50-FineTuning-Fold1-600-epochs.h5')\n",
    "\n",
    "# Se muestra un resumen de la red\n",
    "model.summary()\n",
    "\n",
    "# Configuramos el entrenamiento de la red con los siguientes parámetros:\n",
    "#   - loss='categorical_crossentropy': Función de pérdida para clasificación binaria (glaucoma vs no glaucoma)\n",
    "#   - optimizer=Adam: Optimizador que ajusta los pesos\n",
    "#   - learning_rate=1e-5: Tasa de aprendizaje\n",
    "#   - metrics: Accuracy: Porcentaje de aciertos\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=1e-5),   \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd63f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "print(\"Total test images:\", test_generator.samples)\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)  # verbose=1 muestra progreso\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
